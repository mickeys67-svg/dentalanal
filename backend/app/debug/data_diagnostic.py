"""
ğŸ” ë°ì´í„° ë””ë²„ê¹… ì§„ë‹¨ ì‹œìŠ¤í…œ

í˜„ì¬ ìƒí™©:
- SetupWizardì—ì„œ "ì¡°ì‚¬ì‹œì‘" ë²„íŠ¼ í´ë¦­
- Naver ë°ì´í„° ìˆ˜ì§‘ ì¤‘
- í•˜ì§€ë§Œ ë°ì´í„°ê°€ ì œëŒ€ë¡œ ì €ì¥ë˜ê±°ë‚˜ í‘œì‹œë˜ì§€ ì•ŠìŒ

ì§„ë‹¨ ëª©í‘œ:
1. ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
2. ìŠ¤í¬ë˜í•‘ íŒŒì´í”„ë¼ì¸ ì¶”ì 
3. API ì‘ë‹µ ê²€ì¦
4. ë°ì´í„° ì •ê·œí™” í™•ì¸
5. ë³‘ëª© ì§€ì  ì‹ë³„
"""

import asyncio
import logging
from sqlalchemy import inspect
from sqlalchemy.orm import Session
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)


class DataDiagnostic:
    """ë°ì´í„° ë””ë²„ê¹… ì§„ë‹¨ í´ë˜ìŠ¤"""
    
    def __init__(self, db: Session):
        self.db = db
        self.report = {
            "timestamp": datetime.now().isoformat(),
            "sections": {}
        }
    
    async def run_full_diagnosis(self):
        """ì „ì²´ ì§„ë‹¨ ì‹¤í–‰"""
        
        logger.info("=" * 80)
        logger.info("ğŸ” ë°ì´í„° ë””ë²„ê¹… ì§„ë‹¨ ì‹œì‘")
        logger.info("=" * 80)
        
        # Step 1: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒíƒœ
        await self._diagnose_database_tables()
        
        # Step 2: Client ë°ì´í„° í™•ì¸
        await self._diagnose_clients()
        
        # Step 3: Keywords ë°ì´í„°
        await self._diagnose_keywords()
        
        # Step 4: Targets ë°ì´í„°
        await self._diagnose_targets()
        
        # Step 5: DailyRanks (ì¤‘ìš”!)
        await self._diagnose_daily_ranks()
        
        # Step 6: ìŠ¤í¬ë˜í•‘ ë¡œê·¸
        await self._diagnose_scraping_logs()
        
        # Step 7: API ì‘ë‹µ ìºì‹œ
        await self._diagnose_analytics_cache()
        
        # Step 8: AnalysisHistory (ì‚¬ìš©ì ì¿¼ë¦¬)
        await self._diagnose_analysis_history()
        
        # Step 9: ë°ì´í„° íë¦„ ì¶”ì 
        await self._trace_data_flow()
        
        return self.report
    
    async def _diagnose_database_tables(self):
        """Step 1: ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒíƒœ"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 1ï¸âƒ£ : ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ìƒíƒœ")
        logger.info("="*80)
        
        try:
            # SQLAlchemy inspector ì‚¬ìš©
            inspector = inspect(self.db.bind)
            tables = inspector.get_table_names()
            
            logger.info(f"\nâœ… ì´ í…Œì´ë¸” ìˆ˜: {len(tables)}")
            logger.info("\ní•„ìˆ˜ í…Œì´ë¸” í™•ì¸:")
            
            required_tables = [
                'clients', 'keywords', 'targets', 'daily_ranks',
                'platform_connections', 'analysis_history', 'raw_scraping_logs'
            ]
            
            table_status = {}
            for table in required_tables:
                exists = table in tables
                status = "âœ…" if exists else "âŒ"
                logger.info(f"  {status} {table}")
                table_status[table] = exists
                
                if exists:
                    # ê° í…Œì´ë¸”ì˜ í–‰ ê°œìˆ˜
                    try:
                        count = self.db.execute(f"SELECT COUNT(*) FROM {table}").scalar()
                        logger.info(f"     â””â”€ í–‰ ê°œìˆ˜: {count}")
                    except Exception as e:
                        logger.warning(f"     â””â”€ í–‰ ê°œìˆ˜ í™•ì¸ ì‹¤íŒ¨: {e}")
            
            self.report["sections"]["tables"] = table_status
            
        except Exception as e:
            logger.error(f"âŒ í…Œì´ë¸” ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["tables"] = {"error": str(e)}
    
    async def _diagnose_clients(self):
        """Step 2: Client ë°ì´í„° í™•ì¸"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 2ï¸âƒ£ : Client ë°ì´í„°")
        logger.info("="*80)
        
        try:
            from app.models.models import Client
            
            clients = self.db.query(Client).all()
            
            logger.info(f"\nâœ… ì´ Client ìˆ˜: {len(clients)}")
            
            if clients:
                for client in clients[:5]:  # ì²˜ìŒ 5ê°œë§Œ
                    logger.info(f"\nğŸ“Œ Client: {client.name} ({client.id})")
                    logger.info(f"   â”œâ”€ Agency: {client.agency_id}")
                    logger.info(f"   â”œâ”€ Industry: {client.industry}")
                    logger.info(f"   â”œâ”€ Created: {client.created_at}")
                    logger.info(f"   â””â”€ Keywords: {len(client.keywords)}")
                    
                    # ê° clientì˜ keywords
                    if client.keywords:
                        logger.info(f"      Keywords: {[k.term for k in client.keywords[:3]]}")
                    
                    # ê° clientì˜ DailyRanks
                    daily_rank_count = len(client.daily_ranks)
                    logger.info(f"      DailyRanks: {daily_rank_count}")
            else:
                logger.warning("âš ï¸  Clientê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["clients"] = {
                "count": len(clients),
                "details": [
                    {
                        "name": c.name,
                        "id": str(c.id),
                        "keywords": len(c.keywords),
                        "daily_ranks": len(c.daily_ranks)
                    }
                    for c in clients[:3]
                ]
            }
        
        except Exception as e:
            logger.error(f"âŒ Client ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["clients"] = {"error": str(e)}
    
    async def _diagnose_keywords(self):
        """Step 3: Keywords ë°ì´í„°"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 3ï¸âƒ£ : Keywords ë°ì´í„°")
        logger.info("="*80)
        
        try:
            from app.models.models import Keyword
            
            keywords = self.db.query(Keyword).all()
            
            logger.info(f"\nâœ… ì´ Keyword ìˆ˜: {len(keywords)}")
            
            if keywords:
                logger.info("\nìµœê·¼ Keywords:")
                for kw in keywords[-5:]:
                    logger.info(f"  ğŸ“ {kw.term}")
                    logger.info(f"     â”œâ”€ Client ID: {kw.client_id}")
                    logger.info(f"     â”œâ”€ Category: {kw.category}")
                    logger.info(f"     â””â”€ DailyRanks: {len(kw.daily_ranks)}")
            else:
                logger.warning("âš ï¸  Keywordsê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["keywords"] = {
                "count": len(keywords)
            }
        
        except Exception as e:
            logger.error(f"âŒ Keywords ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["keywords"] = {"error": str(e)}
    
    async def _diagnose_targets(self):
        """Step 4: Targets ë°ì´í„°"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 4ï¸âƒ£ : Targets ë°ì´í„°")
        logger.info("="*80)
        
        try:
            from app.models.models import Target
            
            targets = self.db.query(Target).all()
            
            logger.info(f"\nâœ… ì´ Target ìˆ˜: {len(targets)}")
            
            if targets:
                logger.info("\nTargets (íƒ€ì…ë³„):")
                types = {}
                for target in targets:
                    t = str(target.type)
                    if t not in types:
                        types[t] = 0
                    types[t] += 1
                
                for t_type, count in types.items():
                    logger.info(f"  {t_type}: {count}")
            else:
                logger.warning("âš ï¸  Targetsê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["targets"] = {
                "count": len(targets)
            }
        
        except Exception as e:
            logger.error(f"âŒ Targets ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["targets"] = {"error": str(e)}
    
    async def _diagnose_daily_ranks(self):
        """Step 5: DailyRanks (ë§¤ìš° ì¤‘ìš”!)"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 5ï¸âƒ£ : DailyRanks ë°ì´í„° (ğŸ”´ í•µì‹¬!)")
        logger.info("="*80)
        
        try:
            from app.models.models import DailyRank
            
            daily_ranks = self.db.query(DailyRank).all()
            logger.info(f"\nâœ… ì´ DailyRank ìˆ˜: {len(daily_ranks)}")
            
            if not daily_ranks:
                logger.error("ğŸ”´ DailyRanksê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤! (ë°ì´í„° ìˆ˜ì§‘ì´ ì‹¤íŒ¨í–ˆì„ ê°€ëŠ¥ì„±)")
            
            # ìµœê·¼ DailyRanks
            if daily_ranks:
                recent = sorted(daily_ranks, key=lambda x: x.captured_at, reverse=True)[:5]
                logger.info("\nìµœê·¼ DailyRanks (5ê°œ):")
                
                for dr in recent:
                    logger.info(f"\n  ğŸ” Rank: {dr.rank} ({dr.platform})")
                    logger.info(f"     â”œâ”€ Keyword: {dr.keyword.term if dr.keyword else 'N/A'}")
                    logger.info(f"     â”œâ”€ Target: {dr.target.name if dr.target else 'N/A'}")
                    logger.info(f"     â”œâ”€ Client: {dr.client_id}")
                    logger.info(f"     â”œâ”€ Rank Change: {dr.rank_change}")
                    logger.info(f"     â””â”€ Captured: {dr.captured_at}")
            
            # í”Œë«í¼ë³„ ë¶„í¬
            platform_dist = {}
            for dr in daily_ranks:
                p = str(dr.platform)
                if p not in platform_dist:
                    platform_dist[p] = 0
                platform_dist[p] += 1
            
            logger.info(f"\nDailyRanks ë¶„í¬ (í”Œë«í¼ë³„):")
            for platform, count in platform_dist.items():
                logger.info(f"  {platform}: {count}")
            
            self.report["sections"]["daily_ranks"] = {
                "count": len(daily_ranks),
                "platforms": platform_dist
            }
        
        except Exception as e:
            logger.error(f"âŒ DailyRanks ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            import traceback
            logger.error(traceback.format_exc())
            self.report["sections"]["daily_ranks"] = {"error": str(e)}
    
    async def _diagnose_scraping_logs(self):
        """Step 6: ìŠ¤í¬ë˜í•‘ ë¡œê·¸"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 6ï¸âƒ£ : ìŠ¤í¬ë˜í•‘ ë¡œê·¸")
        logger.info("="*80)
        
        try:
            from app.models.models import RawScrapingLog
            
            logs = self.db.query(RawScrapingLog).all()
            
            logger.info(f"\nâœ… ì´ ìŠ¤í¬ë˜í•‘ ë¡œê·¸: {len(logs)}")
            
            if logs:
                recent = sorted(logs, key=lambda x: x.captured_at, reverse=True)[:3]
                logger.info("\nìµœê·¼ ìŠ¤í¬ë˜í•‘ ë¡œê·¸:")
                
                for log in recent:
                    logger.info(f"\n  ğŸŒ Platform: {log.platform}")
                    logger.info(f"     â”œâ”€ Keyword: {log.keyword}")
                    logger.info(f"     â””â”€ Captured: {log.captured_at}")
            else:
                logger.warning("âš ï¸  ìŠ¤í¬ë˜í•‘ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["scraping_logs"] = {
                "count": len(logs)
            }
        
        except Exception as e:
            logger.error(f"âŒ ìŠ¤í¬ë˜í•‘ ë¡œê·¸ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["scraping_logs"] = {"error": str(e)}
    
    async def _diagnose_analytics_cache(self):
        """Step 7: API ì‘ë‹µ ìºì‹œ"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 7ï¸âƒ£ : Analytics Cache")
        logger.info("="*80)
        
        try:
            from app.models.models import AnalyticsCache
            
            cache = self.db.query(AnalyticsCache).all()
            
            logger.info(f"\nâœ… ì´ ìºì‹œ ì—”íŠ¸ë¦¬: {len(cache)}")
            
            if cache:
                logger.info("\nìºì‹œ ìƒ˜í”Œ:")
                for c in cache[:3]:
                    logger.info(f"  ğŸ”‘ {c.cache_key}")
            else:
                logger.warning("âš ï¸  ìºì‹œê°€ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["analytics_cache"] = {
                "count": len(cache)
            }
        
        except Exception as e:
            logger.error(f"âŒ ìºì‹œ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["analytics_cache"] = {"error": str(e)}
    
    async def _diagnose_analysis_history(self):
        """Step 8: AnalysisHistory"""
        
        logger.info("\n" + "="*80)
        logger.info("Step 8ï¸âƒ£ : Analysis History")
        logger.info("="*80)
        
        try:
            from app.models.models import AnalysisHistory
            
            history = self.db.query(AnalysisHistory).all()
            
            logger.info(f"\nâœ… ì´ Analysis History: {len(history)}")
            
            if history:
                logger.info("\nìµœê·¼ ë¶„ì„:")
                for h in sorted(history, key=lambda x: x.created_at, reverse=True)[:3]:
                    logger.info(f"\n  ğŸ” Keyword: {h.keyword} ({h.platform})")
                    logger.info(f"     â”œâ”€ Is Saved: {h.is_saved}")
                    logger.info(f"     â””â”€ Created: {h.created_at}")
            else:
                logger.warning("âš ï¸  ë¶„ì„ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤!")
            
            self.report["sections"]["analysis_history"] = {
                "count": len(history)
            }
        
        except Exception as e:
            logger.error(f"âŒ ë¶„ì„ ê¸°ë¡ ì§„ë‹¨ ì‹¤íŒ¨: {e}")
            self.report["sections"]["analysis_history"] = {"error": str(e)}
    
    async def _trace_data_flow(self):
        """Step 9: ë°ì´í„° íë¦„ ì¶”ì """
        
        logger.info("\n" + "="*80)
        logger.info("Step 9ï¸âƒ£ : ë°ì´í„° íë¦„ ì¶”ì ")
        logger.info("="*80)
        
        from app.models.models import Client
        
        try:
            clients = self.db.query(Client).all()
            
            logger.info("\nğŸ“Š ë°ì´í„° íë¦„ ë¶„ì„:")
            
            for client in clients[:3]:
                logger.info(f"\nğŸ¥ Client: {client.name}")
                logger.info(f"   â”œâ”€ Keywords: {len(client.keywords)}")
                logger.info(f"   â””â”€ DailyRanks: {len(client.daily_ranks)}")
            
            logger.info("\n" + "="*80)
            logger.info("âœ… ì§„ë‹¨ ì™„ë£Œ")
            logger.info("="*80)
        
        except Exception as e:
            logger.error(f"âŒ íë¦„ ì¶”ì  ì‹¤íŒ¨: {e}")
        
        self.report["sections"]["data_flow"] = {"status": "completed"}
    
    def generate_summary(self):
        """ì§„ë‹¨ ìš”ì•½ ìƒì„±"""
        
        logger.info("\n\n" + "="*80)
        logger.info("ğŸ“‹ ì§„ë‹¨ ìš”ì•½")
        logger.info("="*80)
        
        daily_ranks_count = self.report.get("sections", {}).get("daily_ranks", {}).get("count", 0)
        keywords_count = self.report.get("sections", {}).get("keywords", {}).get("count", 0)
        clients_count = self.report.get("sections", {}).get("clients", {}).get("count", 0)
        
        logger.info(f"\nğŸ“Š ë°ì´í„° í†µê³„:")
        logger.info(f"  Clients: {clients_count}")
        logger.info(f"  Keywords: {keywords_count}")
        logger.info(f"  DailyRanks: {daily_ranks_count}")
        
        # ë¬¸ì œì  ì‹ë³„
        issues = []
        
        if daily_ranks_count == 0:
            issues.append("ğŸ”´ DailyRanksê°€ ë¹„ì–´ìˆìŒ")
        
        if keywords_count == 0:
            issues.append("ğŸ”´ Keywordsê°€ ì—†ìŒ")
        
        if clients_count == 0:
            issues.append("ğŸ”´ Clientsê°€ ì—†ìŒ")
        
        if issues:
            logger.info(f"\nâš ï¸  ë°œê²¬ëœ ë¬¸ì œ:")
            for issue in issues:
                logger.info(f"  {issue}")
        else:
            logger.info(f"\nâœ… ë°ì´í„° ì •ìƒ")
        
        self.report["issues"] = issues
        
        return self.report
