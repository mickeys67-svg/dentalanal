from sqlalchemy.orm import Session
from sqlalchemy import func, and_, extract
from app.models.models import DailyRank, Keyword, MetricsDaily, Campaign, PlatformConnection, Notification
from typing import List, Dict, Optional, Tuple
from uuid import UUID, uuid4
import datetime
import logging
import statistics
from collections import defaultdict
import calendar

class TrendAnalysisService:
    """
    íŠ¸ë Œë“œ ë¶„ì„ ì„œë¹„ìŠ¤

    ì£¼ìš” ê¸°ëŠ¥:
    1. ê³„ì ˆì„± íŒ¨í„´ ê°ì§€ (ì›”ë³„, ìš”ì¼ë³„)
    2. ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜ˆì¸¡
    3. ì‹¤ì‹œê°„ ì•Œë¦¼ ì‹œìŠ¤í…œ
    """

    def __init__(self, db: Session):
        self.db = db
        self.logger = logging.getLogger(__name__)

    def detect_seasonality(
        self,
        client_id: UUID,
        lookback_months: int = 12
    ) -> Dict:
        """
        ê³„ì ˆì„± íŒ¨í„´ ê°ì§€

        ë¶„ì„ í•­ëª©:
        1. ì›”ë³„ ì„±ê³¼ ë³€í™” (MoM Growth)
        2. ìš”ì¼ë³„ ì„±ê³¼ íŒ¨í„´
        3. í”¼í¬ ì‹œì¦Œ ì‹ë³„

        Args:
            client_id: í´ë¼ì´ì–¸íŠ¸ ID
            lookback_months: ë¶„ì„ ê¸°ê°„ (ê°œì›”)

        Returns:
            ê³„ì ˆì„± íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        """
        start_date = datetime.date.today() - datetime.timedelta(days=lookback_months * 30)

        # 1. ì›”ë³„ ì„±ê³¼ ì§‘ê³„
        monthly_performance = self.db.query(
            extract('year', MetricsDaily.date).label('year'),
            extract('month', MetricsDaily.date).label('month'),
            func.sum(MetricsDaily.spend).label('spend'),
            func.sum(MetricsDaily.clicks).label('clicks'),
            func.sum(MetricsDaily.conversions).label('conversions'),
            func.sum(MetricsDaily.impressions).label('impressions')
        ).join(Campaign, MetricsDaily.campaign_id == Campaign.id)\
         .join(PlatformConnection, Campaign.connection_id == PlatformConnection.id)\
         .filter(
            and_(
                PlatformConnection.client_id == client_id,
                MetricsDaily.date >= start_date,
                MetricsDaily.source == 'RECONCILED'
            )
        ).group_by(
            extract('year', MetricsDaily.date),
            extract('month', MetricsDaily.date)
        ).order_by('year', 'month').all()

        monthly_data = []
        prev_spend = None

        for mp in monthly_performance:
            year = int(mp.year)
            month = int(mp.month)
            spend = float(mp.spend or 0)
            conversions = int(mp.conversions or 0)
            clicks = int(mp.clicks or 0)

            # MoM Growth ê³„ì‚°
            mom_growth = None
            if prev_spend is not None and prev_spend > 0:
                mom_growth = ((spend - prev_spend) / prev_spend) * 100

            monthly_data.append({
                "year": year,
                "month": month,
                "month_name": calendar.month_name[month],
                "spend": spend,
                "clicks": clicks,
                "conversions": conversions,
                "mom_growth": round(mom_growth, 1) if mom_growth is not None else None
            })

            prev_spend = spend

        # 2. ìš”ì¼ë³„ ì„±ê³¼ ì§‘ê³„
        dow_performance = self.db.query(
            extract('dow', MetricsDaily.date).label('dow'),  # 0=Sunday, 6=Saturday
            func.sum(MetricsDaily.spend).label('spend'),
            func.sum(MetricsDaily.clicks).label('clicks'),
            func.sum(MetricsDaily.conversions).label('conversions')
        ).join(Campaign, MetricsDaily.campaign_id == Campaign.id)\
         .join(PlatformConnection, Campaign.connection_id == PlatformConnection.id)\
         .filter(
            and_(
                PlatformConnection.client_id == client_id,
                MetricsDaily.date >= start_date,
                MetricsDaily.source == 'RECONCILED'
            )
        ).group_by(extract('dow', MetricsDaily.date)).all()

        dow_map = ["ì¼ìš”ì¼", "ì›”ìš”ì¼", "í™”ìš”ì¼", "ìˆ˜ìš”ì¼", "ëª©ìš”ì¼", "ê¸ˆìš”ì¼", "í† ìš”ì¼"]
        dow_data = []

        for dp in dow_performance:
            dow_idx = int(dp.dow)
            dow_data.append({
                "day_of_week": dow_map[dow_idx],
                "spend": float(dp.spend or 0),
                "clicks": int(dp.clicks or 0),
                "conversions": int(dp.conversions or 0)
            })

        # ìš”ì¼ë³„ ì •ë ¬ (ì›”ìš”ì¼ë¶€í„°)
        dow_data.sort(key=lambda x: dow_map.index(x["day_of_week"]))

        # 3. í”¼í¬ ì‹œì¦Œ ì‹ë³„ (ìƒìœ„ 3ê°œì›”)
        if monthly_data:
            sorted_months = sorted(monthly_data, key=lambda x: x["conversions"], reverse=True)
            peak_seasons = sorted_months[:3]
        else:
            peak_seasons = []

        # 4. íŠ¸ë Œë“œ ë¶„ì„ (ìƒìŠ¹/í•˜ë½)
        if len(monthly_data) >= 3:
            recent_months = monthly_data[-3:]
            avg_growth = statistics.mean([m["mom_growth"] for m in recent_months if m["mom_growth"] is not None])
            trend = "ìƒìŠ¹" if avg_growth > 5 else "í•˜ë½" if avg_growth < -5 else "ì•ˆì •"
        else:
            avg_growth = None
            trend = "ë°ì´í„° ë¶€ì¡±"

        return {
            "analysis_period": f"{start_date} ~ {datetime.date.today()}",
            "monthly_performance": monthly_data,
            "dow_performance": dow_data,
            "peak_seasons": peak_seasons,
            "trend_summary": {
                "direction": trend,
                "avg_mom_growth": round(avg_growth, 1) if avg_growth is not None else None
            }
        }

    def predict_search_trends(
        self,
        client_id: UUID,
        keyword_id: Optional[UUID] = None,
        days: int = 90
    ) -> Dict:
        """
        ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜ˆì¸¡

        Simple Moving Average (SMA) ê¸°ë°˜ ë‹¨ìˆœ ì˜ˆì¸¡ ëª¨ë¸
        ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” ARIMA, Prophet ë“± ê³ ê¸‰ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥

        Args:
            client_id: í´ë¼ì´ì–¸íŠ¸ ID
            keyword_id: íŠ¹ì • í‚¤ì›Œë“œ ID (Noneì´ë©´ ì „ì²´)
            days: ë¶„ì„ ê¸°ê°„

        Returns:
            ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜ˆì¸¡ ê²°ê³¼
        """
        start_date = datetime.datetime.now() - datetime.timedelta(days=days)

        # í‚¤ì›Œë“œë³„ ì¼ì¼ ë“±ì¥ íšŸìˆ˜ ì¶”ì 
        query = self.db.query(
            func.date(DailyRank.captured_at).label('date'),
            Keyword.term,
            func.count(DailyRank.id).label('appearances'),
            func.avg(DailyRank.rank).label('avg_rank')
        ).join(Keyword, DailyRank.keyword_id == Keyword.id)\
         .filter(
            and_(
                Keyword.client_id == client_id,
                DailyRank.captured_at >= start_date
            )
        )

        if keyword_id:
            query = query.filter(Keyword.id == keyword_id)

        query = query.group_by(
            func.date(DailyRank.captured_at),
            Keyword.term
        ).order_by('date')

        results = query.all()

        # í‚¤ì›Œë“œë³„ ë°ì´í„° ê·¸ë£¹í™”
        keyword_trends: Dict[str, List[Dict]] = defaultdict(list)

        for r in results:
            keyword_trends[r.term].append({
                "date": str(r.date),
                "appearances": r.appearances,
                "avg_rank": round(r.avg_rank, 1)
            })

        # ê° í‚¤ì›Œë“œë³„ë¡œ Simple Moving Average ê³„ì‚° (7ì¼)
        predictions = {}

        for keyword, trend_data in keyword_trends.items():
            if len(trend_data) < 7:
                continue

            # ìµœê·¼ 7ì¼ í‰ê· 
            recent_avg = statistics.mean([d["appearances"] for d in trend_data[-7:]])

            # ì „ì²´ í‰ê· 
            overall_avg = statistics.mean([d["appearances"] for d in trend_data])

            # ì˜ˆì¸¡ ë°©í–¥
            if recent_avg > overall_avg * 1.2:
                prediction = "ìƒìŠ¹ ì¶”ì„¸"
            elif recent_avg < overall_avg * 0.8:
                prediction = "í•˜ë½ ì¶”ì„¸"
            else:
                prediction = "ì•ˆì • ì¶”ì„¸"

            predictions[keyword] = {
                "trend_data": trend_data,
                "recent_avg": round(recent_avg, 1),
                "overall_avg": round(overall_avg, 1),
                "prediction": prediction
            }

        return {
            "analysis_period": f"{start_date.date()} ~ {datetime.date.today()}",
            "predictions": predictions
        }

    def create_ranking_drop_alert(
        self,
        client_id: UUID,
        rank_drop_threshold: int = 5
    ) -> List[Dict]:
        """
        ìˆœìœ„ ê¸‰ë½ ì•Œë¦¼

        ì „ì¼ ëŒ€ë¹„ ìˆœìœ„ê°€ {rank_drop_threshold}ìœ„ ì´ìƒ í•˜ë½í•œ í‚¤ì›Œë“œ ê°ì§€

        Args:
            client_id: í´ë¼ì´ì–¸íŠ¸ ID
            rank_drop_threshold: ìˆœìœ„ í•˜ë½ ì„ê³„ê°’ (ê¸°ë³¸ 5ìœ„)

        Returns:
            ìˆœìœ„ ê¸‰ë½ í‚¤ì›Œë“œ ëª©ë¡
        """
        # ìµœê·¼ 2ì¼ê°„ ë°ì´í„° ì¡°íšŒ
        today = datetime.date.today()
        yesterday = today - datetime.timedelta(days=1)
        two_days_ago = today - datetime.timedelta(days=2)

        # ì–´ì œ ìˆœìœ„
        yesterday_ranks = self.db.query(
            Keyword.id,
            Keyword.term,
            func.min(DailyRank.rank).label('rank')
        ).join(DailyRank, DailyRank.keyword_id == Keyword.id)\
         .filter(
            and_(
                Keyword.client_id == client_id,
                func.date(DailyRank.captured_at) == yesterday
            )
        ).group_by(Keyword.id, Keyword.term).all()

        # ê·¸ì €ê»˜ ìˆœìœ„
        two_days_ago_ranks = self.db.query(
            Keyword.id,
            func.min(DailyRank.rank).label('rank')
        ).join(DailyRank, DailyRank.keyword_id == Keyword.id)\
         .filter(
            and_(
                Keyword.client_id == client_id,
                func.date(DailyRank.captured_at) == two_days_ago
            )
        ).group_by(Keyword.id).all()

        # ê·¸ì €ê»˜ ìˆœìœ„ ë§µí•‘
        prev_rank_map = {r.id: r.rank for r in two_days_ago_ranks}

        # ìˆœìœ„ ê¸‰ë½ ê°ì§€
        drops = []

        for yr in yesterday_ranks:
            if yr.id in prev_rank_map:
                prev_rank = prev_rank_map[yr.id]
                curr_rank = yr.rank

                # ìˆœìœ„ í•˜ë½ ê³„ì‚° (ìˆ«ìê°€ ì»¤ì§€ë©´ í•˜ë½)
                rank_change = curr_rank - prev_rank

                if rank_change >= rank_drop_threshold:
                    drops.append({
                        "keyword_id": str(yr.id),
                        "keyword": yr.term,
                        "previous_rank": prev_rank,
                        "current_rank": curr_rank,
                        "drop": rank_change
                    })

                    # ì•Œë¦¼ ìƒì„±
                    notification = Notification(
                        id=uuid4(),
                        client_id=client_id,
                        type="ALERT",
                        title=f"ğŸ“‰ ìˆœìœ„ ê¸‰ë½: {yr.term}",
                        message=f"'{yr.term}' í‚¤ì›Œë“œê°€ {prev_rank}ìœ„ì—ì„œ {curr_rank}ìœ„ë¡œ {rank_change}ìœ„ í•˜ë½í–ˆìŠµë‹ˆë‹¤.",
                        is_read=False
                    )
                    self.db.add(notification)

        if drops:
            self.db.commit()
            self.logger.info(f"Created {len(drops)} ranking drop alerts for client {client_id}")

        return drops

    def create_budget_overspend_alert(
        self,
        client_id: UUID,
        monthly_budget_limit: Optional[float] = None
    ) -> Optional[Dict]:
        """
        ì˜ˆì‚° ì´ˆê³¼ ì•Œë¦¼

        ì›” ì˜ˆì‚° ëŒ€ë¹„ í˜„ì¬ ì†Œì§„ìœ¨ ì²´í¬

        Args:
            client_id: í´ë¼ì´ì–¸íŠ¸ ID
            monthly_budget_limit: ì›” ì˜ˆì‚° í•œë„ (Noneì´ë©´ ìë™ ê³„ì‚°)

        Returns:
            ì˜ˆì‚° ì´ˆê³¼ ì •ë³´ (ì´ˆê³¼í•˜ì§€ ì•Šìœ¼ë©´ None)
        """
        # ì´ë²ˆ ë‹¬ ì‹œì‘ì¼
        today = datetime.date.today()
        month_start = today.replace(day=1)

        # ì´ë²ˆ ë‹¬ ëˆ„ì  ê´‘ê³ ë¹„
        total_spend = self.db.query(
            func.sum(MetricsDaily.spend)
        ).join(Campaign, MetricsDaily.campaign_id == Campaign.id)\
         .join(PlatformConnection, Campaign.connection_id == PlatformConnection.id)\
         .filter(
            and_(
                PlatformConnection.client_id == client_id,
                MetricsDaily.date >= month_start,
                MetricsDaily.source == 'RECONCILED'
            )
        ).scalar()

        total_spend = float(total_spend or 0)

        # ì›” ì˜ˆì‚° í•œë„ ìë™ ê³„ì‚° (ì§€ë‚œ 3ê°œì›” í‰ê· )
        if monthly_budget_limit is None:
            three_months_ago = today - datetime.timedelta(days=90)

            avg_monthly_spend = self.db.query(
                func.avg(func.sum(MetricsDaily.spend))
            ).join(Campaign, MetricsDaily.campaign_id == Campaign.id)\
             .join(PlatformConnection, Campaign.connection_id == PlatformConnection.id)\
             .filter(
                and_(
                    PlatformConnection.client_id == client_id,
                    MetricsDaily.date >= three_months_ago,
                    MetricsDaily.date < month_start,
                    MetricsDaily.source == 'RECONCILED'
                )
            ).group_by(
                extract('year', MetricsDaily.date),
                extract('month', MetricsDaily.date)
            ).scalar()

            monthly_budget_limit = float(avg_monthly_spend or 0) * 1.1  # 10% ì—¬ìœ 

        if monthly_budget_limit <= 0:
            return None

        # ì†Œì§„ìœ¨ ê³„ì‚°
        utilization_rate = (total_spend / monthly_budget_limit) * 100

        # 80% ì´ìƒì´ë©´ ê²½ê³ 
        if utilization_rate >= 80:
            severity = "high" if utilization_rate >= 100 else "medium"

            # ì•Œë¦¼ ìƒì„±
            notification = Notification(
                id=uuid4(),
                client_id=client_id,
                type="ALERT",
                title=f"ğŸ’° ì˜ˆì‚° {'ì´ˆê³¼' if utilization_rate >= 100 else 'ê²½ê³ '}: {round(utilization_rate, 1)}%",
                message=f"ì´ë²ˆ ë‹¬ ê´‘ê³ ë¹„ê°€ {round(total_spend, 0):,.0f}ì›ìœ¼ë¡œ ì˜ˆì‚° ëŒ€ë¹„ {round(utilization_rate, 1)}% ì†Œì§„ë˜ì—ˆìŠµë‹ˆë‹¤.",
                is_read=False
            )
            self.db.add(notification)
            self.db.commit()

            return {
                "total_spend": total_spend,
                "budget_limit": monthly_budget_limit,
                "utilization_rate": round(utilization_rate, 1),
                "severity": severity,
                "month": f"{today.year}-{today.month:02d}"
            }

        return None
